{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trying_out_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoUgsvLxS9Ub2slXgDUxNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arka19das/ML/blob/master/Trying_out_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o86GvqiA52Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#practicing torch\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import scipy \n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTE616Iy6f-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=torch.empty((5,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ZA1V7L8LcE",
        "colab_type": "code",
        "outputId": "29179143-37bb-41d0-bd54-82f10a0f3f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.4057e-35, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 7.0374e+22, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LYQQUOi8OCm",
        "colab_type": "code",
        "outputId": "502de22a-669a-4a9d-8937-dd3f7c3d8d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "y=torch.zeros(5,3,dtype=torch.long)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAtXZaif8r2n",
        "colab_type": "code",
        "outputId": "f874f1e2-edc7-4526-b44c-d79875d3202d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=[1,1 ,1.5,2.0,2.5,8.0]\n",
        "b=(torch.tensor(a))\n",
        "print(b,a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 1.0000, 1.5000, 2.0000, 2.5000, 8.0000]) [1, 1, 1.5, 2.0, 2.5, 8.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANdofiv9NEJ",
        "colab_type": "code",
        "outputId": "ea64e51f-8625-4d7d-eb6a-e0fba8b41178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        " y=x.new_ones(4, 6, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(y)\n",
        "\n",
        "x = torch.randn_like(y, dtype=torch.float)    # override dtype!\n",
        "print(x)          "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.1995,  0.8998, -0.7475, -1.3316, -2.7444,  2.1686],\n",
            "        [ 0.9940,  0.3600, -0.8788, -0.3596,  1.6213,  0.8561],\n",
            "        [-1.4924, -1.4690,  0.9678, -0.3783,  2.2513,  0.3874],\n",
            "        [-0.2509, -0.8962,  0.5396,  0.8538,  0.7624,  0.8320]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxq_4rHj9aZX",
        "colab_type": "code",
        "outputId": "48e00ff2-da63-4f9c-f7b9-085e38980d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHKwUbL6GMpT",
        "colab_type": "code",
        "outputId": "795c3664-8f3f-4756-9318-364aeeb48666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "torch.add(x,y)\n",
        "torch.add(x,y,out=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8005,  1.8998,  0.2525, -0.3316, -1.7444,  3.1686],\n",
              "        [ 1.9940,  1.3600,  0.1212,  0.6404,  2.6213,  1.8561],\n",
              "        [-0.4924, -0.4690,  1.9678,  0.6217,  3.2513,  1.3874],\n",
              "        [ 0.7491,  0.1038,  1.5396,  1.8538,  1.7624,  1.8320]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpqUFZkKGoON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=x.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWe5V6suHufl",
        "colab_type": "code",
        "outputId": "a4e94e98-13ec-4cd8-9c11-eebb8b6f54f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "\n",
        "x.add_(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8005,  1.8998,  0.2525, -0.3316, -1.7444,  3.1686],\n",
              "        [ 1.9940,  1.3600,  0.1212,  0.6404,  2.6213,  1.8561],\n",
              "        [-0.4924, -0.4690,  1.9678,  0.6217,  3.2513,  1.3874],\n",
              "        [ 0.7491,  0.1038,  1.5396,  1.8538,  1.7624,  1.8320]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utRU7xR_IBX4",
        "colab_type": "code",
        "outputId": "6f8039bc-03f5-4fb9-b63e-b0efb01985e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "b=torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8005,  1.8998,  0.2525, -0.3316, -1.7444,  3.1686],\n",
            "        [ 1.9940,  1.3600,  0.1212,  0.6404,  2.6213,  1.8561],\n",
            "        [-0.4924, -0.4690,  1.9678,  0.6217,  3.2513,  1.3874],\n",
            "        [ 0.7491,  0.1038,  1.5396,  1.8538,  1.7624,  1.8320]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDxmrOjkITp2",
        "colab_type": "code",
        "outputId": "1ef6a887-0bc5-4f4d-cf44-ea2c44bf142e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "device = torch.device(\"cuda\")          # a CUDA device object\n",
        "y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "z = x + y\n",
        "print(z)\n",
        "print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.8005,  2.8998,  1.2525,  0.6684, -0.7444,  4.1686],\n",
            "        [ 2.9940,  2.3600,  1.1212,  1.6404,  3.6213,  2.8561],\n",
            "        [ 0.5076,  0.5310,  2.9678,  1.6217,  4.2513,  2.3874],\n",
            "        [ 1.7491,  1.1038,  2.5396,  2.8538,  2.7624,  2.8320]],\n",
            "       device='cuda:0')\n",
            "tensor([[ 1.8005,  2.8998,  1.2525,  0.6684, -0.7444,  4.1686],\n",
            "        [ 2.9940,  2.3600,  1.1212,  1.6404,  3.6213,  2.8561],\n",
            "        [ 0.5076,  0.5310,  2.9678,  1.6217,  4.2513,  2.3874],\n",
            "        [ 1.7491,  1.1038,  2.5396,  2.8538,  2.7624,  2.8320]],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTfR7oGuJofU",
        "colab_type": "code",
        "outputId": "ffb3d17c-9a32-46c2-de45-266f961ba2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDZhv1eWimaq",
        "colab_type": "code",
        "outputId": "6edbadfb-49d4-49b8-bb99-ebcb2ce90f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight\n",
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n",
            "tensor([[ 0.1023,  0.0751,  0.0029, -0.0214,  0.0601,  0.1096, -0.0402, -0.0007,\n",
            "          0.0696,  0.0101]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp9bgXRQiz86",
        "colab_type": "code",
        "outputId": "332d1372-c2dd-4b27-cbd0-d26adfc4117c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))\n",
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.4177, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j_E8lBBi7eQ",
        "colab_type": "code",
        "outputId": "d34f0c11-5ccf-4aef-d009-54ae98b5155d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f29559d94a8>\n",
            "<AddmmBackward object at 0x7f29559d9fd0>\n",
            "<AccumulateGrad object at 0x7f29559d94a8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Kov6OUjAR4",
        "colab_type": "code",
        "outputId": "0c1488f0-7a62-48b0-fdcb-3173cc010082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0039,  0.0074,  0.0106,  0.0004,  0.0172, -0.0068])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J03agDcijbnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsleT-5EjfPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzNaObqxji3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}